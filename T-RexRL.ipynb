{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from DQN import DQN\n",
    "from Experience import ExperienceBuffer\n",
    "from Game import GameEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opts\n",
    "load_model = False\n",
    "checkpoints_path = 'checkpoints/'\n",
    "save_period = 500\n",
    "info_period = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 50\n",
    "gamma = 0.9\n",
    "epsilon = 0.1\n",
    "num_episodes = 10000\n",
    "pre_train = 1000\n",
    "max_ep_len = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create game env, model and exp buff\n",
    "env = GameEnv(2560)\n",
    "dqn = DQN()\n",
    "experience_buffer = ExperienceBuffer(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 seconds before start.\n",
      "Open game tab in full screen mode!\n",
      "model saved\n",
      "|------------------------|\n",
      "total episodes: 1\n",
      "total steps: 17\n",
      "last 10 episodes average reward: 16.0\n",
      "|------------------------|\n",
      "|------------------------|\n",
      "total episodes: 11\n",
      "total steps: 108\n",
      "last 10 episodes average reward: 8.1\n",
      "|------------------------|\n",
      "|------------------------|\n",
      "total episodes: 21\n",
      "total steps: 215\n",
      "last 10 episodes average reward: 9.7\n",
      "|------------------------|\n",
      "|------------------------|\n",
      "total episodes: 31\n",
      "total steps: 306\n",
      "last 10 episodes average reward: 8.1\n",
      "|------------------------|\n",
      "|------------------------|\n",
      "total episodes: 41\n",
      "total steps: 409\n",
      "last 10 episodes average reward: 9.3\n",
      "|------------------------|\n",
      "|------------------------|\n",
      "total episodes: 51\n",
      "total steps: 499\n",
      "last 10 episodes average reward: 8.0\n",
      "|------------------------|\n",
      "|------------------------|\n",
      "total episodes: 61\n",
      "total steps: 595\n",
      "last 10 episodes average reward: 8.6\n",
      "|------------------------|\n",
      "Training stoped\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "total_steps = 0\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "path = tf.train.latest_checkpoint(checkpoints_path)\n",
    "rewards = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        if load_model:\n",
    "            saver.restore(sess, path)\n",
    "        else:\n",
    "            sess.run(init)\n",
    "\n",
    "        for i in range(num_episodes):\n",
    "            episode_buffer = ExperienceBuffer(100000)\n",
    "            episode_reward = 0.0\n",
    "\n",
    "            s, r, d = env.reset(i==0)\n",
    "\n",
    "            for j in range(max_ep_len):\n",
    "                if np.random.rand(1) < epsilon or total_steps < pre_train:\n",
    "                    a = np.random.randint(0, 3)\n",
    "                else:\n",
    "                    a = sess.run(dqn.predict, feed_dict={dqn.x: [s]})[0]\n",
    "\n",
    "                s1, r, d = env.step(a)\n",
    "                episode_buffer.add(np.reshape(np.array([s, a, r, s1, d]), [1,5]))\n",
    "                episode_reward += r\n",
    "                total_steps += 1\n",
    "\n",
    "                if total_steps > pre_train:\n",
    "\n",
    "                    batch = experience_buffer.batch(batch_size)\n",
    "                    Q1 = sess.run(tf.reduce_max(dqn.q_vals, axis=1), feed_dict={dqn.x: np.vstack(batch[:, 3])})\n",
    "                    targetQ = batch[:, 2] + gamma * Q1\n",
    "\n",
    "                    sess.run(dqn.train, feed_dict={dqn.x: np.vstack(batch[:, 0]), \n",
    "                                                   dqn.targetQ: targetQ,\n",
    "                                                   dqn.actions: batch[:, 1]})\n",
    "\n",
    "                if d:\n",
    "                    break\n",
    "            experience_buffer.add(episode_buffer._buffer)\n",
    "            rewards.append(episode_reward)\n",
    "\n",
    "            if i % save_period == 0:\n",
    "                print 'model saved'\n",
    "                saver.save(sess, checkpoints_path, global_step=i)\n",
    "\n",
    "            if i % info_period == 0:\n",
    "                print '|------------------------|'\n",
    "                print ('total episodes: {}\\n'\n",
    "                       'total steps: {}\\n'\n",
    "                       'last {} episodes average reward: {}'.format(i+1, total_steps, info_period, \n",
    "                                                                    np.mean(rewards[-info_period:])))\n",
    "                print '|------------------------|'\n",
    "    except KeyboardInterrupt:\n",
    "        print 'Training stoped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
